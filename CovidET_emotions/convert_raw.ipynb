{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'na': (0, 0),\n",
       "  'na2': (0, 1),\n",
       "  'na3': (0, 2),\n",
       "  'apprehension': (1, 0),\n",
       "  'fear': (1, 1),\n",
       "  'terror': (1, 2),\n",
       "  'acceptance': (2, 0),\n",
       "  'trust': (2, 1),\n",
       "  'admiration': (2, 2),\n",
       "  'serenity': (3, 0),\n",
       "  'joy': (3, 1),\n",
       "  'ecstasy': (3, 2),\n",
       "  'interest': (4, 0),\n",
       "  'anticipation': (4, 1),\n",
       "  'vigilance': (4, 2),\n",
       "  'annoyance': (5, 0),\n",
       "  'anger': (5, 1),\n",
       "  'rage': (5, 2),\n",
       "  'boredom': (6, 0),\n",
       "  'disgust': (6, 1),\n",
       "  'loathing': (6, 2),\n",
       "  'pensiveness': (7, 0),\n",
       "  'sadness': (7, 1),\n",
       "  'grief': (7, 2)},\n",
       " {'na': 0,\n",
       "  'fear': 1,\n",
       "  'trust': 2,\n",
       "  'joy': 3,\n",
       "  'anticipation': 4,\n",
       "  'anger': 5,\n",
       "  'disgust': 6,\n",
       "  'sadness': 7})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plutchik_wheel = {\n",
    "    'na': ['na', 'na2', 'na3'],\n",
    "    'fear': ['apprehension', 'fear', 'terror'],\n",
    "    'trust': ['acceptance', 'trust', 'admiration'],\n",
    "    'joy': ['serenity', 'joy', 'ecstasy'],\n",
    "    'anticipation': ['interest', 'anticipation', 'vigilance'],\n",
    "    'anger': ['annoyance', 'anger', 'rage'],\n",
    "    'disgust': ['boredom', 'disgust', 'loathing'],\n",
    "    'sadness': ['pensiveness', 'sadness', 'grief']\n",
    "}\n",
    "\n",
    "emotions_mapping = {emotion: id for emotion, id in zip(plutchik_wheel.keys(), range(0,8))}\n",
    "\n",
    "intensities_df = pd.DataFrame(plutchik_wheel).rename(columns = emotions_mapping)\n",
    "intensities_mapping = {}\n",
    "for column, series in intensities_df.items():\n",
    "    for index, value in series.items():\n",
    "        intensities_mapping[value] = (column, index)\n",
    "\n",
    "intensities_mapping, emotions_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df_to_csv(path_name):\n",
    "    raw_df = pd.read_json(f'{path_name}.json').T\n",
    "    cleaned_df = pd.DataFrame()\n",
    "    for row_i, row in raw_df.iterrows():\n",
    "        row_dict = {}\n",
    "        row_dict['id'] = row['Reddit ID']\n",
    "        row_dict['t'] = row['Time Created']\n",
    "        row_dict['post'] = row['Reddit Post']\n",
    "        raw_annotations = row['Annotations']\n",
    "\n",
    "        gold_emotions = []\n",
    "        gold_intensities = []\n",
    "\n",
    "        for annot_name, annot in raw_annotations.items():\n",
    "            annot_pattern = re.compile(r'Annotation (\\d+) \\| Assignment ID = (\\w+) \\| Worker ID = (\\w+)')\n",
    "\n",
    "            # Use the regex pattern to extract information\n",
    "            match = re.match(annot_pattern, annot_name)\n",
    "\n",
    "            if match:\n",
    "                annotation_index, assignment_id, worker_id = match.groups()\n",
    "\n",
    "                # Display the extracted information\n",
    "                row_dict[f'annot_{annotation_index}_assignment_id'] = assignment_id\n",
    "                row_dict[f'annot_{annotation_index}_worker_id'] = worker_id\n",
    "                \n",
    "                for entry in annot:\n",
    "                    for category, label in entry.items():\n",
    "                        category = category.lower()\n",
    "                        label = label.lower()\n",
    "                        col_name = f'annot_{annotation_index}_{category}'\n",
    "                        if col_name in row_dict.keys():\n",
    "                            row_dict[col_name][0].append(label)\n",
    "                        else:\n",
    "                            row_dict[col_name] = [[label]]\n",
    "\n",
    "                        if 'emotion' in col_name and label not in gold_emotions:\n",
    "                            gold_emotions.append(label)\n",
    "                        if 'intensity' in col_name and label not in gold_intensities:\n",
    "                            gold_intensities.append(label)\n",
    "            else:\n",
    "                print(\"ERROR: No match found.\")\n",
    "        \n",
    "        gold_emotions = sorted(gold_emotions)\n",
    "        gold_intensities = sorted(gold_intensities)\n",
    "            \n",
    "        row_dict['gold_emotions'] = [gold_emotions]\n",
    "        row_dict['gold_intensities'] = [gold_intensities]\n",
    "\n",
    "        row_dict['gold_emotions_ids'] = [sorted([emotions_mapping[emotion] for emotion in gold_emotions])]\n",
    "        row_dict['gold_intensities_ids'] = [sorted([intensities_mapping[intensity] for intensity in gold_intensities])]\n",
    "\n",
    "\n",
    "        cleaned_df = pd.concat([cleaned_df, pd.DataFrame(index = [row_i], data = row_dict)])\n",
    "\n",
    "    cleaned_df.to_csv(f'{path_name}.csv')\n",
    "    appraisals_df = pd.read_csv('../data/CovidET_appraisals.csv')\n",
    "    pd.merge(cleaned_df, appraisals_df, left_on = 'id', right_on = 'Reddit ID').to_csv(f'{path_name}_w_appraisal.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_paths = ['CovidET-ALL', 'CovidET-ALL-train_val_test/test', 'CovidET-ALL-train_val_test/train', 'CovidET-ALL-train_val_test/val']\n",
    "\n",
    "for path in dataset_paths:\n",
    "    clean_df_to_csv(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dataset_paths = ['CovidET-ALL-train_val_test/test', 'CovidET-ALL-train_val_test/train', 'CovidET-ALL-train_val_test/val']\n",
    "all_df_w_appraisal = pd.read_csv('CovidET-ALL_w_appraisal.csv')\n",
    "\n",
    "for i, path in enumerate(model_dataset_paths):\n",
    "    all_df_w_appraisal.iloc[i*100: (i+1)*100].to_csv(f'{path}_w_appraisal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
